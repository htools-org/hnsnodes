# Handshake regtest

[crawl]

# Logfile
logfile = log/crawl.regtest.log
log_to_console = True

# Network magic number
magic_number = cf9538ae

# Default/fallback port number
port = 14038

# Redis database number
db = 1

# List of DNS seeders to get a subset of reachable nodes
seeders =

# Number of concurrent workers (greenlets)
workers = 2

# Print debug output
debug = True

# Public IP address for network interface
source_address = 0.0.0.0

# Protocol version to use for outgoing version message
protocol_version = 3

# User agent (BIP 0014) to use for outgoing version message
# -----------------------------------------------------------------------------
#                                 NOTE TO USERS
# Please consider changing the user agent before running an instance of this
# crawler. This is so that users will not confuse your crawler with another
# instance that is already running and generating data for the project.
# -----------------------------------------------------------------------------
user_agent = /hnsnodes:0.0-dev/

# Services to use for outgoing network address message
services = 1

# Set to 1 to receive all txs
relay = 0

# Socket timeout
socket_timeout = 5

# Run cron tasks every given interval (how often do you check for state change)
cron_delay = 10

# Take full network snapshot at most at every given interval
snapshot_delay = 60    # 1 minute

# Max. age for peering node to be included in crawl set
max_age = 28800         # 8 hours

# Redis TTL for cached addr response (resultant TTL should be less than max_age)
addr_ttl = 7200         # 2 hours

# Max. upper bound variance rate for addr_ttl (default: 2 to 6 hours TTL)
addr_ttl_var = 200

# Limit max. peers per node to be included in crawl set
peers_per_node = 500

# Attempt to establish connection with IPv6 nodes
ipv6 = False

# Limit max. nodes per IPv6 network prefix
ipv6_prefix = 64
nodes_per_ipv6_prefix = 1

# List of included ASNs
include_asns =

# List of included ASNs from external URL
include_asns_from_url =

# List of excluded ASNs
exclude_asns =

# Exclude IP addresses in private ranges
exclude_private = False

# List of excluded IPv4 networks
exclude_ipv4_networks =

# List of excluded IPv6 networks
exclude_ipv6_networks =

# Exclude IPv4 bogons
exclude_ipv4_bogons_from_urls =

# Exclude IPv6 bogons
exclude_ipv6_bogons_from_urls =

# List of excluded IPv4 networks from external URL
exclude_ipv4_networks_from_url =

# List of excluded IPv6 networks from external URL
exclude_ipv6_networks_from_url =

# Attempt to establish connection with .onion nodes
onion = False

# Tor proxy is required to connect to .onion address
tor_proxies =
    127.0.0.1:9050

# List of initial .onion nodes
onion_nodes =

# Include reachable nodes from https://bitnodes.io/#join-the-network
include_checked = False

# Relative path to directory containing timestamp-prefixed JSON crawl files
crawl_dir = data/crawl/regtest
